{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_TensorFlow/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class MyRNN(tf.keras.Model):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Parameters\n",
        "        self.Wxh = self.add_weight(\n",
        "            shape=(input_size, hidden_size),\n",
        "            initializer=tf.random_normal_initializer(stddev=0.1),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.Whh = self.add_weight(\n",
        "            shape=(hidden_size, hidden_size),\n",
        "            initializer=tf.random_normal_initializer(stddev=0.1),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bh = self.add_weight(\n",
        "            shape=(hidden_size,),\n",
        "            initializer=tf.zeros_initializer(),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        self.Why = self.add_weight(\n",
        "            shape=(hidden_size, output_size),\n",
        "            initializer=tf.random_normal_initializer(stddev=0.1),\n",
        "            trainable=True\n",
        "        )\n",
        "        self.by = self.add_weight(\n",
        "            shape=(output_size,),\n",
        "            initializer=tf.zeros_initializer(),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, x, h0=None):\n",
        "        \"\"\"\n",
        "        x: (seq_len, batch, input_size)\n",
        "        \"\"\"\n",
        "        seq_len = tf.shape(x)[0]\n",
        "        batch = tf.shape(x)[1]\n",
        "\n",
        "        if h0 is None:\n",
        "            h = tf.zeros((batch, self.hidden_size))\n",
        "        else:\n",
        "            h = h0\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            xt = x[t]  # (batch, input_size)\n",
        "\n",
        "            h = tf.tanh(\n",
        "                tf.matmul(xt, self.Wxh) +\n",
        "                tf.matmul(h, self.Whh) +\n",
        "                self.bh\n",
        "            )\n",
        "\n",
        "            y = tf.matmul(h, self.Why) + self.by\n",
        "            outputs.append(y)\n",
        "\n",
        "        return tf.stack(outputs), h\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Data prep\n",
        "# -----------------------------\n",
        "text = \"hello world\"\n",
        "chars = sorted(list(set(text)))\n",
        "stoi = {c:i for i,c in enumerate(chars)}\n",
        "itos = {i:c for c,i in stoi.items()}\n",
        "\n",
        "def encode(s):\n",
        "    return np.array([stoi[c] for c in s], dtype=np.int32)\n",
        "\n",
        "def one_hot(idx, vocab_size):\n",
        "    return tf.one_hot(idx, vocab_size)\n",
        "\n",
        "vocab_size = len(chars)\n",
        "hidden_size = 32\n",
        "\n",
        "model = MyRNN(vocab_size, hidden_size, vocab_size)\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "data = encode(text)\n",
        "\n",
        "# -----------------------------\n",
        "# Training loop\n",
        "# -----------------------------\n",
        "for epoch in range(500):\n",
        "    with tf.GradientTape() as tape:\n",
        "        x = one_hot(data[:-1], vocab_size)  # (seq, vocab)\n",
        "        x = tf.expand_dims(x, 1)            # (seq, batch=1, vocab)\n",
        "        y_true = data[1:]                   # next char\n",
        "\n",
        "        y_pred, _ = model(x)\n",
        "        y_pred = tf.squeeze(y_pred, axis=1)  # (seq, vocab)\n",
        "\n",
        "        loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"epoch {epoch}, loss={loss.numpy():.4f}\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Generation\n",
        "# -----------------------------\n",
        "def generate(model, start=\"h\", length=20):\n",
        "    idx = stoi[start]\n",
        "    h = None\n",
        "    out = start\n",
        "\n",
        "    for _ in range(length):\n",
        "        x = one_hot([idx], vocab_size)\n",
        "        x = tf.expand_dims(x, 1)  # (seq=1, batch=1, vocab)\n",
        "\n",
        "        y, h = model(x, h)\n",
        "        logits = y[-1]  # (1, vocab)\n",
        "\n",
        "        probs = tf.nn.softmax(logits)\n",
        "        idx = tf.random.categorical(tf.math.log(probs), 1).numpy()[0,0]\n",
        "\n",
        "        out += itos[idx]\n",
        "\n",
        "    return out\n",
        "\n",
        "print(generate(model, \"h\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB97lxSTQGOp",
        "outputId": "af419806-fa0b-4a14-8092-bd657a6f33a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss=2.0967\n",
            "epoch 50, loss=0.0067\n",
            "epoch 100, loss=0.0025\n",
            "epoch 150, loss=0.0016\n",
            "epoch 200, loss=0.0011\n",
            "epoch 250, loss=0.0008\n",
            "epoch 300, loss=0.0006\n",
            "epoch 350, loss=0.0005\n",
            "epoch 400, loss=0.0004\n",
            "epoch 450, loss=0.0003\n",
            "hello worldrlworlorld\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "text = \"hello world. this is a simple test for an rnn built from scratch.\"\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "char2idx = {c:i for i,c in enumerate(chars)}\n",
        "idx2char = np.array(chars)\n",
        "\n",
        "encoded = np.array([char2idx[c] for c in text])\n",
        "\n",
        "seq_length = 40\n",
        "step = 3\n",
        "\n",
        "inputs = []\n",
        "targets = []\n",
        "\n",
        "for i in range(0, len(encoded) - seq_length, step):\n",
        "    inputs.append(encoded[i:i+seq_length])\n",
        "    targets.append(encoded[i+seq_length])\n",
        "\n",
        "inputs = np.array(inputs)\n",
        "targets = np.array(targets)\n",
        "\n",
        "embedding_dim = 32\n",
        "rnn_units = 64\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length),\n",
        "    tf.keras.layers.SimpleRNN(rnn_units),\n",
        "    tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(0.01)\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(inputs, targets, epochs=30, batch_size=32)\n",
        "\n",
        "def generate_text(model, start_string, length=200, temperature=1.0):\n",
        "    input_eval = np.array([char2idx[c] for c in start_string])\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    text_generated = []\n",
        "\n",
        "    for _ in range(length):\n",
        "        preds = model(input_eval)\n",
        "        preds = preds / temperature # Removed the extra slicing\n",
        "        predicted_id = tf.random.categorical(preds, num_samples=1)[0,0].numpy()\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "        input_eval = tf.concat([input_eval, [[predicted_id]]], axis=1)\n",
        "        input_eval = input_eval[:, -seq_length:]  # keep window size fixed\n",
        "\n",
        "    return start_string + \"\".join(text_generated)\n",
        "\n",
        "print(generate_text(model, \"hello \"))"
      ],
      "metadata": {
        "id": "mvBW9j-9p_I1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9adfcd3-3597-4e0a-b0d1-ea925fe0b62a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 2.9766\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 2.5642\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 2.2436\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 1.7112\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.6078\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 1.2882\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.0936\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.7423\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.6418\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4340\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2721\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1814\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.1262\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0961\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0608\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0449\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0361\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0298\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0243\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0195\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0154\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0122\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0098\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0081\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0068\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0059\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0052\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0046\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0042\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0038\n",
            "hello pbfchfm .c.ndsucmnfpessbbfosed ndwdbusihpdcpweolddsrecr.danencorbpanuwolmuudpcnuhi.ofepipehcfe.e .ts dmdipsurbddwledsi.oriwifb.wn ft.i wplnalpudnaffsnfdnlcdwpon.fbhmcpmddacbrnwslottnrwfa eiho.onddt. .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}