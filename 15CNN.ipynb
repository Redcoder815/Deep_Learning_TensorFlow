{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redcoder815/Deep_Learning_TensorFlow/blob/main/15CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Z696kmZaAuQZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cross-Correlation Operation"
      ],
      "metadata": {
        "id": "fn7XFFPSBK88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d(X, K):\n",
        "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
        "    h, w = K.shape\n",
        "    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            Y[i, j].assign(tf.reduce_sum(\n",
        "                X[i: i + h, j: j + w] * K))\n",
        "    return Y"
      ],
      "metadata": {
        "id": "E_vE0DnUA_Ee"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "K = tf.constant([[0.0, 1.0], [2.0, 3.0]])\n",
        "corr2d(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF0scLTUBGx1",
        "outputId": "25827d29-3472-41ae-e5bf-1bd834212a09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              "array([[19., 25.],\n",
              "       [37., 43.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic Weight Creation: In Keras, the build method of a tf.keras.layers.Layer subclass is a special method where you typically define and create the layer's weights (like self.weight and self.bias here). It's called automatically the first time the layer is used (i.e., when its call method is invoked) and receives the input shape(s) as an argument.\n",
        "\n",
        "Shape Inference: This allows the layer to dynamically infer the necessary shapes for its weights based on the actual input data shape, rather than requiring you to specify them upfront during __init__. In this Conv2D example, kernel_size is passed to build to determine the shape of the weight and bias.\n",
        "\n",
        "Separation of Concerns: It helps separate the initialization logic (__init__) from the weight creation logic (build). __init__ is for setting up static configuration that doesn't depend on input shapes, while build is for creating variables that do depend on input shapes."
      ],
      "metadata": {
        "id": "9Ej-8W1VCSgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining in __init__:\n",
        "\n",
        "If you define self.weight and self.bias directly in __init__ without knowing the input shape, you would run into a problem. The kernel_size (or the input shape from which kernel_size is derived) is often not available when __init__ is called. The __init__ method is for setting up static configurations that don't depend on the actual input data's shape.\n",
        "\n",
        "For example, in your Conv2D class, self.weight's shape depends on kernel_size. If kernel_size isn't passed to __init__ or cannot be determined at that point, you can't properly define self.weight.\n",
        "\n",
        "Defining in build (as in the current code):\n",
        "\n",
        "Shape Inference: The build method is specifically designed to be called once, the first time the layer is executed (call method is invoked), and it receives the input_shape (or in your case, kernel_size which dictates the weight shape) as an argument. This means you have the necessary information to correctly define the shapes of your weights and biases.\n",
        "\n",
        "Dynamic Sizing: It allows the layer to be flexible. You can define a Conv2D layer without knowing the exact dimensions of the input tensor it will receive. The layer will adapt and build its weights correctly once it sees an input.\n",
        "\n",
        "Best Practice: For Keras Layer subclasses, defining trainable variables (tf.Variable) or using self.add_weight() within the build method is the recommended practice for weights that depend on the input shape.\n",
        "\n",
        "In summary, __init__ is for parameters that are independent of the input shape, while build is for creating parameters (like weights and biases) whose shapes depend on the input data that will flow through the layer."
      ],
      "metadata": {
        "id": "hOz8VYJODljt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Layers"
      ],
      "metadata": {
        "id": "oI5EZLNeC0dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def build(self, kernel_size):\n",
        "        initializer = tf.random_normal_initializer()\n",
        "        self.weight = self.add_weight(name='w', shape=kernel_size,\n",
        "                                      initializer=initializer)\n",
        "        self.bias = self.add_weight(name='b', shape=(1, ),\n",
        "                                    initializer=initializer)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return corr2d(inputs, self.weight) + self.bias"
      ],
      "metadata": {
        "id": "bFcrpKPDBfuX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Edge Detection in Images"
      ],
      "metadata": {
        "id": "_7H01RtLEEdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.Variable(tf.ones((6, 8)))\n",
        "X[:, 2:6].assign(tf.zeros(X[:, 2:6].shape))\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUYCDFZOEJ_s",
        "outputId": "b58d348a-72b6-46cb-c3fb-1f5cdf6ee9c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(6, 8) dtype=float32, numpy=\n",
              "array([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "       [1., 1., 0., 0., 0., 0., 1., 1.],\n",
              "       [1., 1., 0., 0., 0., 0., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = tf.constant([[1.0, -1.0]])"
      ],
      "metadata": {
        "id": "s7tBuUafES0f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = corr2d(X, K)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVE4CHEEWmW",
        "outputId": "a8dcd963-3739-46c5-d5a3-a862d76061b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(6, 7) dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
              "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d(tf.transpose(X), K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3_WaZHzEast",
        "outputId": "8968fbba-b98c-4a38-b656-f20112f55fa9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(8, 5) dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning a Kernel"
      ],
      "metadata": {
        "id": "bWHjmRWUEg2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
        "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
        "conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)\n",
        "\n",
        "# The two-dimensional convolutional layer uses four-dimensional input and\n",
        "# output in the format of (example, height, width, channel), where the batch\n",
        "# size (number of examples in the batch) and the number of channels are both 1\n",
        "X = tf.reshape(X, (1, 6, 8, 1))\n",
        "Y = tf.reshape(Y, (1, 6, 7, 1))\n",
        "lr = 3e-2  # Learning rate\n",
        "\n",
        "Y_hat = conv2d(X)\n",
        "for i in range(10):\n",
        "    # By default, tf.GradientTape watches all tf.Variable objects accessed within its context.\n",
        "    # We can remove 'watch_accessed_variables=False' and the explicit g.watch() call.\n",
        "    with tf.GradientTape() as g:\n",
        "        Y_hat = conv2d(X)\n",
        "        l = (abs(Y_hat - Y)) ** 2\n",
        "        # Compute gradient and update the kernel directly\n",
        "        gradient = g.gradient(l, conv2d.kernel)\n",
        "        conv2d.kernel.assign_sub(lr * gradient)\n",
        "        if (i + 1) % 2 == 0:\n",
        "            print(f'epoch {i + 1}, loss {tf.reduce_sum(l):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj65OBjvEi3k",
        "outputId": "489d08f3-7437-4d2f-f924-07e6ffb358d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss 2.259\n",
            "epoch 4, loss 0.767\n",
            "epoch 6, loss 0.287\n",
            "epoch 8, loss 0.113\n",
            "epoch 10, loss 0.046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reshape(conv2d.get_weights()[0], (1, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGT6m0knGjZC",
        "outputId": "bf419f13-7e5d-4fb7-f792-b5fd8095565d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.9738485, -1.0177288]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "rS-hqdawG-_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down the line tf.reshape(X, (1, ) + X.shape + (1, )) step by step. This operation is crucial for preparing a 2D tensor (X) to be processed by a Keras Conv2D layer, which typically expects a 4D input.\n",
        "\n",
        "X: This is your input tensor, which in the example of comp_conv2d, starts as a 2D tensor (e.g., (8, 8)).\n",
        "\n",
        "X.shape: This attribute returns the current shape of the tensor X as a tuple. So, if X is an (8, 8) tensor, X.shape will be (8, 8).\n",
        "\n",
        "(1, ): This creates a tuple containing a single integer 1. The comma after the 1 is important; it tells Python that (1, ) is a tuple with one element, not just an integer 1 in parentheses.\n",
        "\n",
        "+ (Tuple Concatenation): The + operator, when used with tuples, concatenates them. Let's see how the new shape tuple is formed:\n",
        "\n",
        "First, (1, ) + X.shape combines the initial (1, ) with X.shape. If X.shape is (8, 8), this becomes (1, ) + (8, 8) = (1, 8, 8).\n",
        "Next, this intermediate tuple (1, 8, 8) is concatenated with the final (1, ): (1, 8, 8) + (1, ) = (1, 8, 8, 1).\n",
        "In summary, tf.reshape(X, (1, ) + X.shape + (1, )) takes your original 2D tensor X (e.g., height x width) and reshapes it into a 4D tensor with the following dimensions:\n",
        "\n",
        "The first 1 adds a batch dimension. This is because convolutional layers typically process data in batches, even if you're only feeding one image at a time.\n",
        "X.shape (e.g., 8, 8) provides the height and width dimensions.\n",
        "The final 1 adds a channel dimension. For grayscale images or single-feature maps, the number of channels is 1.\n",
        "So, an (8, 8) tensor X becomes a (1, 8, 8, 1) tensor, which is the expected (batch_size, height, width, channels) format for tf.keras.layers.Conv2D."
      ],
      "metadata": {
        "id": "fpWpNgmbHd1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the comp_conv2d function, Y is the output of the conv2d layer. As we discussed earlier, Keras Conv2D layers typically output a 4D tensor with the shape (batch_size, height, width, channels).\n",
        "\n",
        "Let's assume Y has a shape like (1, 8, 8, 1) (one example in the batch, 8x8 spatial dimensions, one channel).\n",
        "\n",
        "Y.shape: This will be the tuple (1, 8, 8, 1).\n",
        "\n",
        "Y.shape[1:3]: This is a Python slice operation on the Y.shape tuple. It selects elements from index 1 (inclusive) up to index 3 (exclusive).\n",
        "\n",
        "Index 0 is 1 (batch size)\n",
        "Index 1 is 8 (height)\n",
        "Index 2 is 8 (width)\n",
        "Index 3 is 1 (channels)\n",
        "So, Y.shape[1:3] extracts (8, 8).\n",
        "\n",
        "tf.reshape(Y, (8, 8)): This takes the 4D tensor Y and reshapes it into a 2D tensor with the dimensions (height, width).\n",
        "\n",
        "Why is this done?\n",
        "\n",
        "The comp_conv2d helper function's purpose is to encapsulate the process of applying a 2D convolution and then returning a 2D result. Since the input X was originally 2D, and for many visual tasks (like simply displaying the resulting feature map), you often want to go back to a 2D representation, the tf.reshape(Y, Y.shape[1:3]) step effectively \"strips\" away the batch dimension (at index 0) and the channel dimension (at index 3), leaving only the height and width of the feature map. This makes the output easier to interpret or use in subsequent 2D operations."
      ],
      "metadata": {
        "id": "3BAfTm--H2xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define a helper function to calculate convolutions. It initializes\n",
        "# the convolutional layer weights and performs corresponding dimensionality\n",
        "# elevations and reductions on the input and output\n",
        "def comp_conv2d(conv2d, X):\n",
        "    # (1, 1) indicates that batch size and the number of channels are both 1\n",
        "    X = tf.reshape(X, (1, ) + X.shape + (1, ))\n",
        "    Y = conv2d(X)\n",
        "    # Strip the first two dimensions: examples and channels\n",
        "    return tf.reshape(Y, Y.shape[1:3])\n",
        "# 1 row and column is padded on either side, so a total of 2 rows or columns\n",
        "# are added\n",
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same')\n",
        "X = tf.random.uniform(shape=(8, 8))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXT3wl5yG-m7",
        "outputId": "cdc3aa92-22d6-4d47-cadd-dd26a1b475dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras.layers.Conv2D layer, it means that the convolutional layer will apply padding to the input such that the output feature map has the same height and width as the input feature map, assuming a stride of 1.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "Goal: Maintain the spatial dimensions (height and width) of the input. If your input is (H, W) and your kernel is (k_h, k_w), and you use padding='same' with a stride of 1, the output will also be (H, W).\n",
        "\n",
        "How it works: Keras (and TensorFlow) automatically calculates the amount of padding needed on all sides of the input to achieve this same output size. It adds zeros around the borders of the input image. If the required padding is an odd number, it will often add one more pixel of padding to one side (e.g., bottom or right) than the other.\n",
        "\n",
        "In your notebook's example: You can see this in action with cells eXT3wl5yG-m7 and qTAD_hRIH-Kc:\n",
        "\n",
        "In eXT3wl5yG-m7, the input X is (8, 8). When conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same') is applied, comp_conv2d(conv2d, X).shape returns TensorShape([8, 8]). The output size matches the input size.\n",
        "Similarly, in qTAD_hRIH-Kc, with kernel_size=(5, 3) and padding='same', the (8, 8) input also results in an TensorShape([8, 8]) output.\n",
        "This is useful because it simplifies network design, allowing you to stack multiple convolutional layers without constantly shrinking the feature map's spatial dimensions, making it easier to maintain resolution and context through the network."
      ],
      "metadata": {
        "id": "D6Rjsr_QJPaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use a convolution kernel with height 5 and width 3. The padding on\n",
        "# either side of the height and width are 2 and 1, respectively\n",
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(5, 3), padding='same')\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTAD_hRIH-Kc",
        "outputId": "c6f3d273-23e7-415d-eea8-64a30063e8de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stride"
      ],
      "metadata": {
        "id": "IDA2n-jdJhaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same', strides=2)\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3AUGfSzJj3-",
        "outputId": "90a1b65c-3938-4c27-fb1c-500d806e07a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you set padding='valid' in a tf.keras.layers.Conv2D layer, it means that no padding is applied to the input. The convolution operation is performed only on the 'valid' parts of the input where the kernel fully overlaps with the input data. This almost always results in an output feature map that is smaller than the input feature map.\n",
        "\n",
        "Here's a breakdown:\n",
        "\n",
        "Goal: Perform convolution without adding extra zeros around the borders of the input.\n",
        "\n",
        "How it works: The convolution kernel slides across the input. If the kernel cannot fully fit within the input dimensions at a given position, that position is skipped. This means that the output feature map will be smaller than the input. The reduction in size depends on the kernel_size and strides.\n",
        "\n",
        "Formula for output size (for padding='valid'):\n",
        "\n",
        "Output Height = (Input Height - Kernel Height) / Stride Height + 1\n",
        "Output Width = (Input Width - Kernel Width) / Stride Width + 1 (The results are floored if they are not integers).\n",
        "In your notebook's example 9rZD7ZLXKFV8:\n",
        "\n",
        "Input X has shape (8, 8).\n",
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3, 5), padding='valid', strides=(3, 4))\n",
        "kernel_size=(3, 5) means kernel height is 3, kernel width is 5.\n",
        "strides=(3, 4) means stride height is 3, stride width is 4.\n",
        "Let's calculate the output shape:\n",
        "\n",
        "Height: (8 - 3) / 3 + 1 = 5 / 3 + 1 = 1.66... + 1 = 2 (after flooring).\n",
        "Width: (8 - 5) / 4 + 1 = 3 / 4 + 1 = 0.75 + 1 = 1.75 = 1 (after flooring).\n",
        "Indeed, comp_conv2d(conv2d, X).shape returns TensorShape([2, 1]), matching these calculations. This shows a significant reduction in spatial dimensions compared to padding='same'."
      ],
      "metadata": {
        "id": "jQXlv01MMfnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3,5), padding='valid',\n",
        "                                strides=(3, 4))\n",
        "comp_conv2d(conv2d, X).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rZD7ZLXKFV8",
        "outputId": "a81d3d36-7057-4203-fb16-5e4e994389ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Input Channels"
      ],
      "metadata": {
        "id": "bCr2PeOwM_uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in(X, K):\n",
        "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
        "    return tf.reduce_sum([corr2d(x, k) for x, k in zip(X, K)], axis=0)"
      ],
      "metadata": {
        "id": "QnCtjCD8NBse"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
        "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
        "K = tf.constant([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
        "\n",
        "corr2d_multi_in(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQagFVugNLLo",
        "outputId": "4cb129ac-70b4-4fef-f745-973c44ffb071"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[ 56.,  72.],\n",
              "       [104., 120.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Output Channels"
      ],
      "metadata": {
        "id": "Nkq_pfzYNWCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out(X, K):\n",
        "    # Iterate through the 0th dimension of K, and each time, perform\n",
        "    # cross-correlation operations with input X. All of the results are\n",
        "    # stacked together\n",
        "    return tf.stack([corr2d_multi_in(X, k) for k in K], 0)"
      ],
      "metadata": {
        "id": "SjgOWsgKNYH9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = tf.stack((K, K + 1, K + 2), 0)\n",
        "K.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb6KWAm4NhWu",
        "outputId": "307d9074-8f41-4ba3-913b-4afdb7ab4c38"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr2d_multi_in_out(X, K)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhTQIhnkNlU0",
        "outputId": "f2e33651-d5d5-4963-9f62-00fb2b1047f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
              "array([[[ 56.,  72.],\n",
              "        [104., 120.]],\n",
              "\n",
              "       [[ 76., 100.],\n",
              "        [148., 172.]],\n",
              "\n",
              "       [[ 96., 128.],\n",
              "        [192., 224.]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1x1 Convolutional Layer"
      ],
      "metadata": {
        "id": "TbMVU5veNp2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr2d_multi_in_out_1x1(X, K):\n",
        "    c_i, h, w = X.shape\n",
        "    c_o = K.shape[0]\n",
        "    X = tf.reshape(X, (c_i, h * w))\n",
        "    K = tf.reshape(K, (c_o, c_i))\n",
        "    # Matrix multiplication in the fully connected layer\n",
        "    Y = tf.matmul(K, X)\n",
        "    return tf.reshape(Y, (c_o, h, w))"
      ],
      "metadata": {
        "id": "9SaiqXQVNr03"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.normal((3, 3, 3), 0, 1)\n",
        "K = tf.random.normal((2, 3, 1, 1), 0, 1)\n",
        "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
        "Y2 = corr2d_multi_in_out(X, K)\n",
        "assert float(tf.reduce_sum(tf.abs(Y1 - Y2))) < 1e-6"
      ],
      "metadata": {
        "id": "4dETTE7nN-pL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum Pooling and Average Pooling"
      ],
      "metadata": {
        "id": "bszNtImsQ0V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pool2d(X, pool_size, mode='max'):\n",
        "    p_h, p_w = pool_size\n",
        "    Y = tf.Variable(tf.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w +1)))\n",
        "    for i in range(Y.shape[0]):\n",
        "        for j in range(Y.shape[1]):\n",
        "            if mode == 'max':\n",
        "                Y[i, j].assign(tf.reduce_max(X[i: i + p_h, j: j + p_w]))\n",
        "            elif mode =='avg':\n",
        "                Y[i, j].assign(tf.reduce_mean(X[i: i + p_h, j: j + p_w]))\n",
        "    return Y"
      ],
      "metadata": {
        "id": "D3FfEK56Q2Ln"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
        "pool2d(X, (2, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An2zVOmLQ_60",
        "outputId": "7d68aee4-5a17-4db8-cfc8-320244d594dd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              "array([[4., 5.],\n",
              "       [7., 8.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d(X, (2, 2), 'avg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ppnfYyMREa9",
        "outputId": "6f88bece-9c94-4fef-d39a-8563fd612dc2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
              "array([[2., 3.],\n",
              "       [5., 6.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding and Stride"
      ],
      "metadata": {
        "id": "VJy3gyEbRMsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.reshape(tf.range(16, dtype=tf.float32), (1, 4, 4, 1))\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfPDbwP3RO0Q",
        "outputId": "bd75e555-2775-4145-cc46-4c7b8c3d0484"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 4, 1), dtype=float32, numpy=\n",
              "array([[[[ 0.],\n",
              "         [ 1.],\n",
              "         [ 2.],\n",
              "         [ 3.]],\n",
              "\n",
              "        [[ 4.],\n",
              "         [ 5.],\n",
              "         [ 6.],\n",
              "         [ 7.]],\n",
              "\n",
              "        [[ 8.],\n",
              "         [ 9.],\n",
              "         [10.],\n",
              "         [11.]],\n",
              "\n",
              "        [[12.],\n",
              "         [13.],\n",
              "         [14.],\n",
              "         [15.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3])\n",
        "# Pooling has no model parameters, hence it needs no initialization\n",
        "pool2d(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPoFOnrYSHA-",
        "outputId": "c01ab1f7-c8dc-476c-ca9f-5a046b951c5f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[10.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "paddings = tf.constant([[0, 0], [1,0], [1,0], [0,0]]):\n",
        "\n",
        "This line defines the padding to be applied to the X tensor. The paddings tensor has a shape of (num_dimensions, 2), where each inner list [before, after] specifies the number of padding units to add before and after that dimension.\n",
        "[0, 0] for the batch dimension (no padding).\n",
        "[1, 0] for the height dimension (adds 1 row of zeros at the top).\n",
        "[1, 0] for the width dimension (adds 1 column of zeros on the left).\n",
        "[0, 0] for the channel dimension (no padding).\n",
        "X_padded = tf.pad(X, paddings, \"CONSTANT\"):\n",
        "\n",
        "This applies the defined paddings to the input tensor X (which was a 4x4 tensor reshaped to (1, 4, 4, 1) from the previous cell). The \"CONSTANT\" mode fills the padded areas with zeros.\n",
        "After this, X_padded will have a shape of (1, 5, 5, 1) (1 batch, 5 height, 5 width, 1 channel).\n",
        "pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='valid', strides=2):\n",
        "\n",
        "This initializes a MaxPool2D layer.\n",
        "pool_size=[3, 3]: The pooling window is 3x3 pixels.\n",
        "padding='valid': This is crucial. It means no additional padding will be applied by the pooling layer itself. The pooling operation will only be performed where the 3x3 window completely fits within the (already padded) X_padded tensor.\n",
        "strides=2: The pooling window moves 2 steps at a time across both height and width dimensions.\n",
        "pool2d(X_padded):\n",
        "\n",
        "This applies the configured max pooling layer to the X_padded tensor.\n",
        "Given X_padded is (1, 5, 5, 1), a 3x3 pool with strides=2 and padding='valid' results in an output shape of (1, 2, 2, 1). The output values are the maximums found in each 3x3 window as it slides over the padded input with a stride of 2.\n",
        "The output shows [[[[ 5.], [ 7.]], [[13.], [15.]]]], which corresponds to the maximum values extracted from each 3x3 pooling region within the padded input."
      ],
      "metadata": {
        "id": "f9A5SNrbVP_T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfb3435c"
      },
      "source": [
        "### Detailed Explanation of Max Pooling Output (5, 7, 13, 15)\n",
        "\n",
        "Let's trace the `MaxPool2D` operation step-by-step to understand how the output values `5, 7, 13, 15` are derived.\n",
        "\n",
        "First, recall the initial `X` tensor (before reshaping to `(1, 4, 4, 1)`):\n",
        "```\n",
        "[[ 0.  1.  2.  3.]\n",
        " [ 4.  5.  6.  7.]\n",
        " [ 8.  9. 10. 11.]\n",
        " [12. 13. 14. 15.]]\n",
        "```\n",
        "\n",
        "When `X` is reshaped to `(1, 4, 4, 1)` and then padded with `paddings = tf.constant([[0, 0], [1,0], [1,0], [0,0]])` (adding one row of zeros at the top and one column of zeros on the left), the `X_padded` tensor (simplified to 2D for clarity, ignoring batch and channel dimensions) looks like this:\n",
        "\n",
        "`X_padded` (5x5 matrix):\n",
        "```\n",
        "[[ 0.  0.  0.  0.  0.]\n",
        " [ 0.  0.  1.  2.  3.]\n",
        " [ 0.  4.  5.  6.  7.]\n",
        " [ 0.  8.  9. 10. 11.]\n",
        " [ 0. 12. 13. 14. 15.]]\n",
        "```\n",
        "\n",
        "Now, we apply `MaxPool2D(pool_size=[3, 3], padding='valid', strides=2)`:\n",
        "\n",
        "1.  **First Output Value: 5**\n",
        "    *   The 3x3 pooling window starts at `(0, 0)` of `X_padded`.\n",
        "    *   It covers this region:\n",
        "        ```\n",
        "        [[ 0.  0.  0.]\n",
        "         [ 0.  0.  1.]\n",
        "         [ 0.  4.  5.]]\n",
        "        ```\n",
        "    *   The maximum value in this window is `5`.\n",
        "\n",
        "2.  **Second Output Value: 7**\n",
        "    *   The window moves 2 steps to the right (due to `strides=2`), starting at `(0, 2)` of `X_padded`.\n",
        "    *   It covers this region:\n",
        "        ```\n",
        "        [[ 0.  0.  0.]\n",
        "         [ 1.  2.  3.]\n",
        "         [ 5.  6.  7.]]\n",
        "        ```\n",
        "    *   The maximum value here is `7`.\n",
        "\n",
        "3.  **Third Output Value: 13**\n",
        "    *   The window moves 2 steps down from its previous position (relative to the start of the `X_padded`), starting at `(2, 0)` of `X_padded`.\n",
        "    *   It covers this region:\n",
        "        ```\n",
        "        [[ 0.  4.  5.]\n",
        "         [ 0.  8.  9.]\n",
        "         [ 0. 12. 13.]]\n",
        "        ```\n",
        "    *   The maximum value is `13`.\n",
        "\n",
        "4.  **Fourth Output Value: 15**\n",
        "    *   The window moves 2 steps to the right from the previous position, starting at `(2, 2)` of `X_padded`.\n",
        "    *   It covers this region:\n",
        "        ```\n",
        "        [[ 5.  6.  7.]\n",
        "         [ 9. 10. 11.]\n",
        "         [13. 14. 15.]]\n",
        "        ```\n",
        "    *   The maximum value is `15`.\n",
        "\n",
        "These four maximum values form the `(1, 2, 2, 1)` output tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfff7ffc",
        "outputId": "df24a3ff-9725-4ebf-8525-64159dcb5cb8"
      },
      "source": [
        "X = tf.reshape(tf.range(16, dtype=tf.float32), (1, 4, 4, 1))\n",
        "paddings = tf.constant([[0, 0], [1,0], [1,0], [0,0]])\n",
        "X_padded = tf.pad(X, paddings, \"CONSTANT\")\n",
        "pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='valid',\n",
        "                                   strides=2)\n",
        "pool2d(X_padded)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
              "array([[[[ 5.],\n",
              "         [ 7.]],\n",
              "\n",
              "        [[13.],\n",
              "         [15.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paddings = tf.constant([[0, 0], [0, 0], [1, 1], [0, 0]])\n",
        "X_padded = tf.pad(X, paddings, \"CONSTANT\")\n",
        "\n",
        "pool2d = tf.keras.layers.MaxPool2D(pool_size=[2, 3], padding='valid',\n",
        "                                   strides=(2, 3))\n",
        "pool2d(X_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXzgpi0mWVd_",
        "outputId": "d31eeb12-f234-4bf2-be4a-36a123d79a91"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
              "array([[[[ 5.],\n",
              "         [ 7.]],\n",
              "\n",
              "        [[13.],\n",
              "         [15.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Channels"
      ],
      "metadata": {
        "id": "K7pBrMDuWgI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate along `dim=3` due to channels-last syntax\n",
        "X = tf.concat([X, X + 1], 3)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFIZekkbWh6b",
        "outputId": "92a221ce-b348-4368-eeae-7215ac173e81"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=\n",
              "array([[[[ 0.,  1.],\n",
              "         [ 1.,  2.],\n",
              "         [ 2.,  3.],\n",
              "         [ 3.,  4.]],\n",
              "\n",
              "        [[ 4.,  5.],\n",
              "         [ 5.,  6.],\n",
              "         [ 6.,  7.],\n",
              "         [ 7.,  8.]],\n",
              "\n",
              "        [[ 8.,  9.],\n",
              "         [ 9., 10.],\n",
              "         [10., 11.],\n",
              "         [11., 12.]],\n",
              "\n",
              "        [[12., 13.],\n",
              "         [13., 14.],\n",
              "         [14., 15.],\n",
              "         [15., 16.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paddings = tf.constant([[0, 0], [1,0], [1,0], [0,0]])\n",
        "X_padded = tf.pad(X, paddings, \"CONSTANT\")\n",
        "pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='valid',\n",
        "                                   strides=2)\n",
        "pool2d(X_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKl54j70WvTu",
        "outputId": "1e4a9e0e-3ef4-409d-fb7d-59b027c42fd2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 2, 2), dtype=float32, numpy=\n",
              "array([[[[ 5.,  6.],\n",
              "         [ 7.,  8.]],\n",
              "\n",
              "        [[13., 14.],\n",
              "         [15., 16.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The layer_summary method is a utility function used to inspect the output shapes of each layer within the neural network model. It's particularly useful for:\n",
        "\n",
        "Debugging Network Architecture: It helps to verify that the dimensions of your tensors are changing as expected after each convolutional, pooling, or dense layer. Incorrect dimensions can lead to errors later in the model.\n",
        "Understanding Tensor Flow: By printing the output shape after each layer, you can easily see how the spatial dimensions (height and width) are reduced by pooling layers or convolutional layers with strides, and how the number of channels changes.\n",
        "Determining Flattening Size: Before a Flatten() layer, layer_summary shows the exact 3D shape (batch_size, height, width, channels) which helps in understanding what size the tensor will be flattened into, which is critical for setting up the subsequent Dense layers correctly."
      ],
      "metadata": {
        "id": "fn4Zb5hvYigq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(tf.keras.Model):\n",
        "    \"\"\"The LeNet-5 model.\"\"\"\n",
        "    def __init__(self, lr=0.1, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n",
        "                                   activation='relu', padding='same'),\n",
        "            tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "            tf.keras.layers.Conv2D(filters=16, kernel_size=5,\n",
        "                                   activation='relu'),\n",
        "            tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(120, activation='relu'),\n",
        "            tf.keras.layers.Dense(84, activation='relu'),\n",
        "            tf.keras.layers.Dense(num_classes)])\n",
        "\n",
        "    def call(self, X):\n",
        "      return self.net(X)\n",
        "\n",
        "    def layer_summary(self, X_shape):\n",
        "        X = tf.random.normal(X_shape)\n",
        "        for layer in self.net.layers:\n",
        "            X = layer(X)\n",
        "            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n"
      ],
      "metadata": {
        "id": "h-sxnTuuXdeU"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "model.layer_summary((1, 28, 28, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AWwmom7X6fO",
        "outputId": "f2b0051d-c2ac-4fb8-b07a-708206a75e83"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2D output shape:\t (1, 28, 28, 6)\n",
            "AveragePooling2D output shape:\t (1, 14, 14, 6)\n",
            "Conv2D output shape:\t (1, 10, 10, 16)\n",
            "AveragePooling2D output shape:\t (1, 5, 5, 16)\n",
            "Flatten output shape:\t (1, 400)\n",
            "Dense output shape:\t (1, 120)\n",
            "Dense output shape:\t (1, 84)\n",
            "Dense output shape:\t (1, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "# Reshape images to (num_samples, height, width, channels) and normalize to [0, 1]\n",
        "# Fashion MNIST images are 28x28 and grayscale, so channels = 1\n",
        "X_train = tf.cast(tf.reshape(X_train, (-1, 28, 28, 1)), tf.float32) / 255.0\n",
        "X_test = tf.cast(tf.reshape(X_test, (-1, 28, 28, 1)), tf.float32) / 255.0\n",
        "\n",
        "# Cast labels to int64 as expected by some TF operations\n",
        "y_train = tf.cast(y_train, tf.int64)\n",
        "y_test = tf.cast(y_test, tf.int64)\n",
        "\n",
        "# Hyperparameters (from original notebook context)\n",
        "batch_size = 256\n",
        "lr = 0.1\n",
        "num_epochs = 10\n",
        "\n",
        "# Create tf.data.Dataset objects for efficient data pipeline\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)"
      ],
      "metadata": {
        "id": "YYs9U5kCZNxJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr)"
      ],
      "metadata": {
        "id": "GlYppNumZVfA"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bVTX4FUTZbpp"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2PdGC33Zgdc",
        "outputId": "27c0d1a9-695c-4d5e-99ce-7e4fe54afa72"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 126ms/step - accuracy: 0.4819 - loss: 1.4285 - val_accuracy: 0.7197 - val_loss: 0.7756\n",
            "Epoch 2/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.7674 - loss: 0.6175 - val_accuracy: 0.7461 - val_loss: 0.6810\n",
            "Epoch 3/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.8072 - loss: 0.5142 - val_accuracy: 0.8107 - val_loss: 0.5046\n",
            "Epoch 4/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.8290 - loss: 0.4583 - val_accuracy: 0.8201 - val_loss: 0.4860\n",
            "Epoch 5/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.8414 - loss: 0.4247 - val_accuracy: 0.8237 - val_loss: 0.4731\n",
            "Epoch 6/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 125ms/step - accuracy: 0.8507 - loss: 0.3977 - val_accuracy: 0.8251 - val_loss: 0.4607\n",
            "Epoch 7/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.8579 - loss: 0.3797 - val_accuracy: 0.8273 - val_loss: 0.4736\n",
            "Epoch 8/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 123ms/step - accuracy: 0.8633 - loss: 0.3644 - val_accuracy: 0.8438 - val_loss: 0.4214\n",
            "Epoch 9/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 128ms/step - accuracy: 0.8698 - loss: 0.3468 - val_accuracy: 0.7921 - val_loss: 0.5348\n",
            "Epoch 10/10\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 123ms/step - accuracy: 0.8713 - loss: 0.3430 - val_accuracy: 0.8584 - val_loss: 0.3904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_dataset, verbose=0)\n",
        "print(f\"Final validation accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "aVEHRnSwczjb",
        "outputId": "34dcd6d6-a0bb-44c5-9b58-4bb733570a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final validation accuracy: 0.8584\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}